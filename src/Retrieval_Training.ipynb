{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b759bea-375b-4d91-a3b7-9c4ad365df3c",
   "metadata": {},
   "source": [
    "# ML Model Test: Retrieval\n",
    "\n",
    "This is a follow up of the TensorFlow Recommenders tutorials. On this notebook, we will be focusing on the \"Retrieval\" stage of a Recommender System. All the information is in the following [link](https://www.tensorflow.org/recommenders/examples/basic_retrieval).<br>\n",
    "We strongly recommend creating a **virtual environment** before running the following code. Let's start by getting our dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7034ec8e-a438-4b58-af6f-a021af640016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-recommenders in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: tensorflow>=2.6.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow-recommenders) (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow-recommenders) (0.12.0)\n",
      "Requirement already satisfied: six in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from absl-py>=0.1.6->tensorflow-recommenders) (1.16.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (0.2.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (12.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.21.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (0.37.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (0.22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (3.10.0.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.41.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorflow>=2.6.0->tensorflow-recommenders) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (58.0.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (2.26.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (2021.10.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.6.0->tensorflow-recommenders) (3.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (d:\\programas\\anaconda\\envs\\tensorflow_dev\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-recommenders\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8d2e04-9be0-4c99-9437-dbaba7bfdce6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports\n",
    "\n",
    "Next, let's invoke the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47306f4c-0be3-4619-9575-d4e0296e8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a753549-b20f-4a02-8ea3-7be69da9698c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This is included in the TensorFlow library. We intend to use the MovieLens ratings and movies dataset. All the data will be considered for the `train` split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75f64cf6-2216-4e03-8d1a-f19a2afd5c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ratings data.\n",
    "ratings = tfds.load(\"ccp2_capstone_ratings\", split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load(\"ccp2_capstone_media_items\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478db7d-9111-4fa7-acd5-6746f472652c",
   "metadata": {},
   "source": [
    "Let's take a look at the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791f869d-3c6f-4d74-bdf3-9ff09175cede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: \n",
      "{'media_id': b'357',\n",
      " 'media_title': b'Sifan',\n",
      " 'user_id': b'138',\n",
      " 'user_rating': 4.0}\n",
      "Movie: \n",
      "{'media_id': b'1198', 'media_title': b'Classroom\\\\xe2\\\\x98\\\\x86Crisis'}\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "    print(\"Rating: \")\n",
    "    pprint.pprint(x)\n",
    "\n",
    "for x in movies.take(1).as_numpy_iterator():\n",
    "    print(\"Movie: \")\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92bb925-c9ab-402a-b2aa-362233733be8",
   "metadata": {},
   "source": [
    "You can modify the limits of the previous for-loops if you would like to see more examples. The next thing to do is to process the data. We only need `user_id` and `movie_title` for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f919265-fed3-4fce-97bc-f63fd1b19841",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"media_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "})\n",
    "movies = movies.map(lambda x: x[\"media_title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804017e8-8d37-4cb9-9635-fb082ea29da5",
   "metadata": {},
   "source": [
    "Let's now split the set into `train` and `test` sets. This is for having ways of validation after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63cd5464-aa3c-440e-bb4c-a83ebbe1be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb78129b-b12f-4130-962b-bbbf51ad827b",
   "metadata": {},
   "source": [
    "Next, we will identify unique `user_id`s and `movie_title`s. This is for having the vocabulary necessary for embedding vectors mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "824ebbb6-e622-4d40-b436-5c46c8b3f1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'', b\"'Til There Was You\", b'.hack//Tasogare no Udewa Densetsu',\n",
       "       b'100-nichikan Ikita Wani X Bourbon', b'101 Dalmatians',\n",
       "       b'12-sai.: Chicchana Mune no Tokimeki', b'187', b'1year',\n",
       "       b'2 Days in the Valley', b'2020 Nyeon Ujuui Wonder Kiddy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa6b0d-370d-4e08-89ad-052de6f6470e",
   "metadata": {},
   "source": [
    "## Implementing\n",
    "\n",
    "This is a two-tower Retrieval model, so we will build them separately and put them back together at the end. \n",
    "\n",
    "### Query Tower\n",
    "\n",
    "The first thing to do is define the dimensionality of the query. In other words, decide how many candidates we want to fetch in this stage. The higher the value, the slower and prone to overfitting it gets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fa4def8-9a5c-463f-870a-c4108fba72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d4691-71e6-4a12-b5b9-87975d67c263",
   "metadata": {},
   "source": [
    "Let's now define our model using the `Keras` library. It defines the layers of your Neural Network. Our objective here is to convert words from IDs and movie titles into integers we can use for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08672e21-2165-4f6a-a97c-72d28a9043de",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_user_ids, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f2e50-6c6e-4d98-bd99-02598f2f8493",
   "metadata": {},
   "source": [
    "### Candidate Tower\n",
    "\n",
    "Similar to Query Tower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "135b2085-4638-418f-b5d1-992f7b51686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=unique_movie_titles, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0681d9-446b-4541-b0fa-83038ad04197",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "This is the method we will use to measure the \"accuracy\" of our model, using the implicit negatives for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29dc4b4a-5ba5-476d-b7dd-808ebc9ad20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a7e029-8fe4-4058-919d-55c6eb588b70",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "We will use the `Retrieval` task object for wrapping together loss function and metric computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4850be03-0ee5-4c20-b63c-eb6f473b6ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b16a78-1866-4af8-a4c4-08b995c06a9c",
   "metadata": {},
   "source": [
    "### Full model\n",
    "\n",
    "Here we put all the pieces together for creating our model. There is a high level of abstraction in the following code for selecting the appropriate training loop that matches our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ca8a164-f37d-4e89-9ec3-2a0921a6ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, user_model, movie_model):\n",
    "    super().__init__()\n",
    "    self.movie_model: tf.keras.Model = movie_model\n",
    "    self.user_model: tf.keras.Model = user_model\n",
    "    self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    # We pick out the user features and pass them into the user model.\n",
    "    user_embeddings = self.user_model(features[\"user_id\"])\n",
    "    # And pick out the movie features and pass them into the movie model,\n",
    "    # getting embeddings back.\n",
    "    positive_movie_embeddings = self.movie_model(features[\"movie_title\"])\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb9fa6-ce70-4b51-8fde-d52d43809e4b",
   "metadata": {},
   "source": [
    "## Fitting and Evaluating\n",
    "\n",
    "This makes use of `Keras` functionalities. Let's start by  instantiating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c278d2ae-136e-4379-a844-d47d28cee497",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc86965-3a39-4b74-8e6b-e8e04ad1360e",
   "metadata": {},
   "source": [
    "Shuffle, batch, and cache the training and evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bd50cc2-d650-4bf4-aa8b-c2b3454857e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b869de3-ef72-40a3-ade5-2f49734d15d2",
   "metadata": {},
   "source": [
    "Finally, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a974dc-5ac2-460b-bacd-dadcd6947eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 11s 788ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0101 - factorized_top_k/top_10_categorical_accuracy: 0.0213 - factorized_top_k/top_50_categorical_accuracy: 0.1011 - factorized_top_k/top_100_categorical_accuracy: 0.1753 - loss: 69893.2592 - regularization_loss: 0.0000e+00 - total_loss: 69893.2592\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 8s 754ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0031 - factorized_top_k/top_5_categorical_accuracy: 0.0201 - factorized_top_k/top_10_categorical_accuracy: 0.0399 - factorized_top_k/top_50_categorical_accuracy: 0.1722 - factorized_top_k/top_100_categorical_accuracy: 0.2962 - loss: 67524.1726 - regularization_loss: 0.0000e+00 - total_loss: 67524.1726\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 8s 804ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0036 - factorized_top_k/top_5_categorical_accuracy: 0.0241 - factorized_top_k/top_10_categorical_accuracy: 0.0474 - factorized_top_k/top_50_categorical_accuracy: 0.1930 - factorized_top_k/top_100_categorical_accuracy: 0.3225 - loss: 66282.8913 - regularization_loss: 0.0000e+00 - total_loss: 66282.8913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d6b22a0d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e41510-e840-468f-b340-b8e5040e544d",
   "metadata": {},
   "source": [
    ">As the model trains, the loss is falling and a set of top-k retrieval metrics is updated. These tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time.\n",
    "\n",
    "> -- <cite>TensorFlow Recommenders - Retrieval Tutorial</cite>\n",
    "\n",
    "Having that in mind, we can now evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8cbc5d3-aa87-42dc-9934-d049bd272a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 288ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0012 - factorized_top_k/top_5_categorical_accuracy: 0.0100 - factorized_top_k/top_10_categorical_accuracy: 0.0237 - factorized_top_k/top_50_categorical_accuracy: 0.1257 - factorized_top_k/top_100_categorical_accuracy: 0.2385 - loss: 31071.1029 - regularization_loss: 0.0000e+00 - total_loss: 31071.1029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0011500000255182385,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.009999999776482582,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.023749999701976776,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.1256999969482422,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.23849999904632568,\n",
       " 'loss': 28304.404296875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 28304.404296875}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787c758f-d514-4c66-90e8-c01ec4d1acb7",
   "metadata": {},
   "source": [
    "As expected, the performance on unknown data is not as good as in the training set, meaning our model is not overfitting. We also need to take into account that the model is re-recommending movies already watched by the user.\n",
    "\n",
    "## Predictions\n",
    "\n",
    "By using the `tfrs.layers.factorized_top_k.BruteForce` layer. Since it is a brute-force approach, it is slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78f3f2bf-7c8f-4b32-a85f-205388fc98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Gundam vs Hello Kitty' b'Jumanji' b'Sleepless in Seattle']\n"
     ]
    }
   ],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f5b43-93e8-45eb-9580-e2836a118e20",
   "metadata": {},
   "source": [
    "## Model Serving\n",
    "\n",
    "We will pack our two-tower retrieval model into a single exportable as a `SavedModel` so we can deploy it with `TensorFlow Serving`. We just need the `BruteForce` layer from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb0ed8d-a9d0-4b80-a736-7d733a796c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Documentos\\Code Chrysalis\\ccp2\\ccp2-capstone-recommender-retrieval\\src\\../models/retrieval/00000123/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\Documentos\\Code Chrysalis\\ccp2\\ccp2-capstone-recommender-retrieval\\src\\../models/retrieval/00000123/assets\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "path = os.path.join(os.getcwd(), \"../models/retrieval/00000123/\")\n",
    "\n",
    "# Save the index.\n",
    "tf.saved_model.save(index, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dd4023-78b1-4c41-a141-f0826ea7a906",
   "metadata": {},
   "source": [
    "The next step is to deploy our model in Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c0936c-1f02-40cf-b1db-467b325e1ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
